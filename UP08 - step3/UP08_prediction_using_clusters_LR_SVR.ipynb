{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load your original dataset\n",
    "df = pd.read_excel(r\"UP08.xlsx\", index_col='Date_Time')\n",
    "df = df[['dissolvedoxygenmeasured']]\n",
    "df=df['2017-04-01':'2021-03-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Datasets:\n",
    "# Cluster 1: November, December, January, February\n",
    "# Cluster 2: June, July, August\n",
    "# Cluster 3: April, May, September, October, March"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Datasets:\n",
    "# Cluster 1: November, December, January, February"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your original dataset\n",
    "df = pd.read_excel(r\"UP08.xlsx\", index_col='Date_Time')\n",
    "df = df[['dissolvedoxygenmeasured']]\n",
    "df=df['2017-04-01':'2021-03-31']\n",
    "\n",
    "# Filter DataFrame for the months November, December, January, February\n",
    "df = df[df.index.month.isin([11, 12, 1, 2])]\n",
    "\n",
    "# Print or use the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df['2017-04-01':'2020-03-31']\n",
    "df_test=df['2020-04-01':]\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "import numpy \n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-2):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back+2, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "def percentage_error(actual, predicted):\n",
    "    res = numpy.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=df.values\n",
    "X, Y = create_dataset(datasets, 5)\n",
    "\n",
    "train_size = 8664\n",
    "test_size = 2880\n",
    "trainX, testX = X[0:train_size], X[train_size:]\n",
    "trainY, testY = Y[0:train_size], Y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "start_time = time.time()\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "X_train=pd.DataFrame(trainX)\n",
    "Y_train=pd.DataFrame(trainY)\n",
    "X_test=pd.DataFrame(testX)\n",
    "Y_test=pd.DataFrame(testY)\n",
    "\n",
    "sc_X = MinMaxScaler()\n",
    "sc_y = MinMaxScaler()\n",
    "\n",
    "X= sc_X.fit_transform(X_train)\n",
    "y= sc_y.fit_transform(Y_train)\n",
    "X1= sc_X.transform(X_test)\n",
    "y1= sc_y.transform(Y_test)\n",
    "y=y.ravel()\n",
    "y1=y1.ravel()  \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X,y)\n",
    "y_pred_train_lr= lr.predict(X)\n",
    "y_pred_test_lr= lr.predict(X1)\n",
    "\n",
    "y_pred_train_lr=pd.DataFrame(y_pred_train_lr)\n",
    "y_pred_test_lr=pd.DataFrame(y_pred_test_lr)\n",
    "\n",
    "y1=pd.DataFrame(y1)\n",
    "y=pd.DataFrame(y)\n",
    "\n",
    "y_pred_test1_lr= sc_y.inverse_transform (y_pred_test_lr)\n",
    "y_pred_train1_lr=sc_y.inverse_transform (y_pred_train_lr)\n",
    "\n",
    "y_test= sc_y.inverse_transform (y1)\n",
    "y_train= sc_y.inverse_transform (y)\n",
    "\n",
    "y_pred_test1_rf=pd.DataFrame(y_pred_test1_lr)\n",
    "y_pred_train1_rf=pd.DataFrame(y_pred_train1_lr)\n",
    "\n",
    "y_test= pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "#summarize the fit of the model on train data\n",
    "mape_train_lr_c1 = mean_absolute_percentage_error(y_train,y_pred_train1_lr)\n",
    "rmse_train_lr_c1 = sqrt(mean_squared_error(y_train,y_pred_train1_lr))\n",
    "mae_train_lr_c1 = metrics.mean_absolute_error(y_train,y_pred_train1_lr)\n",
    "\n",
    "# summarize the fit of the model on test data\n",
    "mape_test_lr_c1 = mean_absolute_percentage_error(y_test,y_pred_test1_lr)\n",
    "rmse_test_lr_c1 = sqrt(mean_squared_error(y_test,y_pred_test1_lr))\n",
    "mae_test_lr_c1 = metrics.mean_absolute_error(y_test,y_pred_test1_lr)\n",
    "\n",
    "# train scores\n",
    "print(\"The metrics for the training data are: \")\n",
    "print(mape_train_lr_c1)\n",
    "print(rmse_train_lr_c1)\n",
    "print(mae_train_lr_c1)\n",
    "\n",
    "# test scores\n",
    "print(\"The metrics for the testing data are: \")\n",
    "print(mape_test_lr_c1)\n",
    "print(rmse_test_lr_c1)\n",
    "print(mae_test_lr_c1)\n",
    "\n",
    "lr_time=time.time() - start_time\n",
    "print(\"--- %s seconds - Linear Regression ---\" % (lr_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "start_time = time.time()\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "X_train=pd.DataFrame(trainX)\n",
    "Y_train=pd.DataFrame(trainY)\n",
    "X_test=pd.DataFrame(testX)\n",
    "Y_test=pd.DataFrame(testY)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "X= sc_X.fit_transform(X_train)\n",
    "y= sc_y.fit_transform(Y_train)\n",
    "X1= sc_X.transform(X_test)\n",
    "y1= sc_y.transform(Y_test)\n",
    "y=y.ravel()\n",
    "y1=y1.ravel()  \n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "svr.fit(X,y)\n",
    "y_pred_train_svr= svr.predict(X)\n",
    "y_pred_test_svr= svr.predict(X1)\n",
    "\n",
    "y_pred_train_svr=pd.DataFrame(y_pred_train_svr)\n",
    "y_pred_test_svr=pd.DataFrame(y_pred_test_svr)\n",
    "\n",
    "y1=pd.DataFrame(y1)\n",
    "y=pd.DataFrame(y)\n",
    "\n",
    "y_pred_test1_svr= sc_y.inverse_transform (y_pred_test_svr)\n",
    "y_pred_train1_svr=sc_y.inverse_transform (y_pred_train_svr)\n",
    "\n",
    "y_test= sc_y.inverse_transform (y1)\n",
    "y_train= sc_y.inverse_transform (y)\n",
    "\n",
    "y_pred_test1_rf=pd.DataFrame(y_pred_test1_svr)\n",
    "y_pred_train1_rf=pd.DataFrame(y_pred_train1_svr)\n",
    "\n",
    "y_test= pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "#summarize the fit of the model on train data\n",
    "mape_train_svr_c1 = mean_absolute_percentage_error(y_train,y_pred_train1_svr)\n",
    "rmse_train_svr_c1 = sqrt(mean_squared_error(y_train,y_pred_train1_svr))\n",
    "mae_train_svr_c1 = metrics.mean_absolute_error(y_train,y_pred_train1_svr)\n",
    "\n",
    "# summarize the fit of the model on test data\n",
    "mape_test_svr_c1 = mean_absolute_percentage_error(y_test,y_pred_test1_svr)\n",
    "rmse_test_svr_c1 = sqrt(mean_squared_error(y_test,y_pred_test1_svr))\n",
    "mae_test_svr_c1 = metrics.mean_absolute_error(y_test,y_pred_test1_svr)\n",
    "\n",
    "# train scores\n",
    "print(\"The metrics for the training data are: \")\n",
    "print(mape_train_svr_c1)\n",
    "print(rmse_train_svr_c1)\n",
    "print(mae_train_svr_c1)\n",
    "\n",
    "# test scores\n",
    "print(\"The metrics for the testing data are: \")\n",
    "print(mape_test_svr_c1)\n",
    "print(rmse_test_svr_c1)\n",
    "print(mae_test_svr_c1)\n",
    "\n",
    "svr_time=time.time() - start_time\n",
    "print(\"--- %s seconds - Support Vector Regression ---\" % (svr_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 2: June, July, August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your original dataset\n",
    "df = pd.read_excel(r\"UP08.xlsx\", index_col='Date_Time')\n",
    "df = df[['dissolvedoxygenmeasured']]\n",
    "df=df['2017-04-01':'2021-03-31']\n",
    "\n",
    "# Assuming you have already loaded and filtered your DataFrame df\n",
    "# If not, you can use the provided code to load and filter it\n",
    "\n",
    "# Filter DataFrame for the months 'June', 'July', 'August'\n",
    "df = df[df.index.month.isin([6, 7, 8])]\n",
    "\n",
    "# Print or use the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df['2017-04-01':'2020-03-31']\n",
    "df_test=df['2020-04-01':]\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "import numpy \n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-2):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back+2, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "def percentage_error(actual, predicted):\n",
    "    res = numpy.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=df.values\n",
    "X, Y = create_dataset(datasets, 5)\n",
    "\n",
    "train_size = 6624\n",
    "test_size = 2208\n",
    "trainX, testX = X[0:train_size], X[train_size:]\n",
    "trainY, testY = Y[0:train_size], Y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "start_time = time.time()\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "X_train=pd.DataFrame(trainX)\n",
    "Y_train=pd.DataFrame(trainY)\n",
    "X_test=pd.DataFrame(testX)\n",
    "Y_test=pd.DataFrame(testY)\n",
    "\n",
    "sc_X = MinMaxScaler()\n",
    "sc_y = MinMaxScaler()\n",
    "\n",
    "X= sc_X.fit_transform(X_train)\n",
    "y= sc_y.fit_transform(Y_train)\n",
    "X1= sc_X.transform(X_test)\n",
    "y1= sc_y.transform(Y_test)\n",
    "y=y.ravel()\n",
    "y1=y1.ravel()  \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X,y)\n",
    "y_pred_train_lr= lr.predict(X)\n",
    "y_pred_test_lr= lr.predict(X1)\n",
    "\n",
    "y_pred_train_lr=pd.DataFrame(y_pred_train_lr)\n",
    "y_pred_test_lr=pd.DataFrame(y_pred_test_lr)\n",
    "\n",
    "y1=pd.DataFrame(y1)\n",
    "y=pd.DataFrame(y)\n",
    "\n",
    "y_pred_test1_lr= sc_y.inverse_transform (y_pred_test_lr)\n",
    "y_pred_train1_lr=sc_y.inverse_transform (y_pred_train_lr)\n",
    "\n",
    "y_test= sc_y.inverse_transform (y1)\n",
    "y_train= sc_y.inverse_transform (y)\n",
    "\n",
    "y_pred_test1_rf=pd.DataFrame(y_pred_test1_lr)\n",
    "y_pred_train1_rf=pd.DataFrame(y_pred_train1_lr)\n",
    "\n",
    "y_test= pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "#summarize the fit of the model on train data\n",
    "mape_train_lr_c2 = mean_absolute_percentage_error(y_train,y_pred_train1_lr)\n",
    "rmse_train_lr_c2 = sqrt(mean_squared_error(y_train,y_pred_train1_lr))\n",
    "mae_train_lr_c2 = metrics.mean_absolute_error(y_train,y_pred_train1_lr)\n",
    "\n",
    "# summarize the fit of the model on test data\n",
    "mape_test_lr_c2 = mean_absolute_percentage_error(y_test,y_pred_test1_lr)\n",
    "rmse_test_lr_c2 = sqrt(mean_squared_error(y_test,y_pred_test1_lr))\n",
    "mae_test_lr_c2 = metrics.mean_absolute_error(y_test,y_pred_test1_lr)\n",
    "\n",
    "# train scores\n",
    "print(\"The metrics for the training data are: \")\n",
    "print(mape_train_lr_c2)\n",
    "print(rmse_train_lr_c2)\n",
    "print(mae_train_lr_c2)\n",
    "\n",
    "# test scores\n",
    "print(\"The metrics for the testing data are: \")\n",
    "print(mape_test_lr_c2)\n",
    "print(rmse_test_lr_c2)\n",
    "print(mae_test_lr_c2)\n",
    "lr_time=time.time() - start_time\n",
    "print(\"--- %s seconds - Linear Regression ---\" % (lr_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "start_time = time.time()\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "X_train=pd.DataFrame(trainX)\n",
    "Y_train=pd.DataFrame(trainY)\n",
    "X_test=pd.DataFrame(testX)\n",
    "Y_test=pd.DataFrame(testY)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "X= sc_X.fit_transform(X_train)\n",
    "y= sc_y.fit_transform(Y_train)\n",
    "X1= sc_X.transform(X_test)\n",
    "y1= sc_y.transform(Y_test)\n",
    "y=y.ravel()\n",
    "y1=y1.ravel()  \n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "svr.fit(X,y)\n",
    "y_pred_train_svr= svr.predict(X)\n",
    "y_pred_test_svr= svr.predict(X1)\n",
    "\n",
    "y_pred_train_svr=pd.DataFrame(y_pred_train_svr)\n",
    "y_pred_test_svr=pd.DataFrame(y_pred_test_svr)\n",
    "\n",
    "y1=pd.DataFrame(y1)\n",
    "y=pd.DataFrame(y)\n",
    "\n",
    "y_pred_test1_svr= sc_y.inverse_transform (y_pred_test_svr)\n",
    "y_pred_train1_svr=sc_y.inverse_transform (y_pred_train_svr)\n",
    "\n",
    "y_test= sc_y.inverse_transform (y1)\n",
    "y_train= sc_y.inverse_transform (y)\n",
    "\n",
    "y_pred_test1_rf=pd.DataFrame(y_pred_test1_svr)\n",
    "y_pred_train1_rf=pd.DataFrame(y_pred_train1_svr)\n",
    "\n",
    "y_test= pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "#summarize the fit of the model on train data\n",
    "mape_train_svr_c2 = mean_absolute_percentage_error(y_train,y_pred_train1_svr)\n",
    "rmse_train_svr_c2 = sqrt(mean_squared_error(y_train,y_pred_train1_svr))\n",
    "mae_train_svr_c2 = metrics.mean_absolute_error(y_train,y_pred_train1_svr)\n",
    "\n",
    "# summarize the fit of the model on test data\n",
    "mape_test_svr_c2 = mean_absolute_percentage_error(y_test,y_pred_test1_svr)\n",
    "rmse_test_svr_c2 = sqrt(mean_squared_error(y_test,y_pred_test1_svr))\n",
    "mae_test_svr_c2 = metrics.mean_absolute_error(y_test,y_pred_test1_svr)\n",
    "\n",
    "# train scores\n",
    "print(\"The metrics for the training data are: \")\n",
    "print(mape_train_svr_c2)\n",
    "print(rmse_train_svr_c2)\n",
    "print(mae_train_svr_c2)\n",
    "\n",
    "# test scores\n",
    "print(\"The metrics for the testing data are: \")\n",
    "print(mape_test_svr_c2)\n",
    "print(rmse_test_svr_c2)\n",
    "print(mae_test_svr_c2)\n",
    "\n",
    "svr_time=time.time() - start_time\n",
    "print(\"--- %s seconds - Support Vector Regression ---\" % (svr_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 2017, May 2017, September 2017, October 2017, March 2018\n",
    "# April 2018, May 2018, September 2018, October 2018, March 2019\n",
    "# April 2019, May 2019, September 2019, October 2019, March 2020\n",
    "# April 2020, May 2020, September 2020, October 2020, March 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your original dataset\n",
    "df = pd.read_excel(r\"UP08.xlsx\", index_col='Date_Time')\n",
    "df = df[['dissolvedoxygenmeasured']]\n",
    "df=df['2017-04-01':'2021-03-31']\n",
    "\n",
    "\n",
    "# Filter DataFrame for the months April, May, September, October, March\n",
    "\n",
    "df = df[df.index.month.isin([3, 4, 5, 9, 10])]\n",
    "\n",
    "# Print or use the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df['2017-04-01':'2020-03-31']\n",
    "df_test=df['2020-04-01':]\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "import numpy \n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-2):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back+2, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "def percentage_error(actual, predicted):\n",
    "    res = numpy.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=df.values\n",
    "X, Y = create_dataset(datasets, 5)\n",
    "\n",
    "train_size = 11016\n",
    "test_size = 3672\n",
    "trainX, testX = X[0:train_size], X[train_size:]\n",
    "trainY, testY = Y[0:train_size], Y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "start_time = time.time()\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "X_train=pd.DataFrame(trainX)\n",
    "Y_train=pd.DataFrame(trainY)\n",
    "X_test=pd.DataFrame(testX)\n",
    "Y_test=pd.DataFrame(testY)\n",
    "\n",
    "sc_X = MinMaxScaler()\n",
    "sc_y = MinMaxScaler()\n",
    "\n",
    "X= sc_X.fit_transform(X_train)\n",
    "y= sc_y.fit_transform(Y_train)\n",
    "X1= sc_X.transform(X_test)\n",
    "y1= sc_y.transform(Y_test)\n",
    "y=y.ravel()\n",
    "y1=y1.ravel()  \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X,y)\n",
    "y_pred_train_lr= lr.predict(X)\n",
    "y_pred_test_lr= lr.predict(X1)\n",
    "\n",
    "y_pred_train_lr=pd.DataFrame(y_pred_train_lr)\n",
    "y_pred_test_lr=pd.DataFrame(y_pred_test_lr)\n",
    "\n",
    "y1=pd.DataFrame(y1)\n",
    "y=pd.DataFrame(y)\n",
    "\n",
    "y_pred_test1_lr= sc_y.inverse_transform (y_pred_test_lr)\n",
    "y_pred_train1_lr=sc_y.inverse_transform (y_pred_train_lr)\n",
    "\n",
    "y_test= sc_y.inverse_transform (y1)\n",
    "y_train= sc_y.inverse_transform (y)\n",
    "\n",
    "y_pred_test1_rf=pd.DataFrame(y_pred_test1_lr)\n",
    "y_pred_train1_rf=pd.DataFrame(y_pred_train1_lr)\n",
    "\n",
    "y_test= pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "#summarize the fit of the model on train data\n",
    "mape_train_lr_c3 = mean_absolute_percentage_error(y_train,y_pred_train1_lr)\n",
    "rmse_train_lr_c3 = sqrt(mean_squared_error(y_train,y_pred_train1_lr))\n",
    "mae_train_lr_c3 = metrics.mean_absolute_error(y_train,y_pred_train1_lr)\n",
    "\n",
    "# summarize the fit of the model on test data\n",
    "mape_test_lr_c3 = mean_absolute_percentage_error(y_test,y_pred_test1_lr)\n",
    "rmse_test_lr_c3 = sqrt(mean_squared_error(y_test,y_pred_test1_lr))\n",
    "mae_test_lr_c3 = metrics.mean_absolute_error(y_test,y_pred_test1_lr)\n",
    "\n",
    "# train scores\n",
    "print(\"The metrics for the training data are: \")\n",
    "print(mape_train_lr_c3)\n",
    "print(rmse_train_lr_c3)\n",
    "print(mae_train_lr_c3)\n",
    "\n",
    "# test scores\n",
    "print(\"The metrics for the testing data are: \")\n",
    "print(mape_test_lr_c3)\n",
    "print(rmse_test_lr_c3)\n",
    "print(mae_test_lr_c3)\n",
    "\n",
    "lr_time=time.time() - start_time\n",
    "print(\"--- %s seconds - Linear Regression ---\" % (lr_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "start_time = time.time()\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "X_train=pd.DataFrame(trainX)\n",
    "Y_train=pd.DataFrame(trainY)\n",
    "X_test=pd.DataFrame(testX)\n",
    "Y_test=pd.DataFrame(testY)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "X= sc_X.fit_transform(X_train)\n",
    "y= sc_y.fit_transform(Y_train)\n",
    "X1= sc_X.transform(X_test)\n",
    "y1= sc_y.transform(Y_test)\n",
    "y=y.ravel()\n",
    "y1=y1.ravel()  \n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "svr.fit(X,y)\n",
    "y_pred_train_svr= svr.predict(X)\n",
    "y_pred_test_svr= svr.predict(X1)\n",
    "\n",
    "y_pred_train_svr=pd.DataFrame(y_pred_train_svr)\n",
    "y_pred_test_svr=pd.DataFrame(y_pred_test_svr)\n",
    "\n",
    "y1=pd.DataFrame(y1)\n",
    "y=pd.DataFrame(y)\n",
    "\n",
    "y_pred_test1_svr= sc_y.inverse_transform (y_pred_test_svr)\n",
    "y_pred_train1_svr=sc_y.inverse_transform (y_pred_train_svr)\n",
    "\n",
    "y_test= sc_y.inverse_transform (y1)\n",
    "y_train= sc_y.inverse_transform (y)\n",
    "\n",
    "y_pred_test1_rf=pd.DataFrame(y_pred_test1_svr)\n",
    "y_pred_train1_rf=pd.DataFrame(y_pred_train1_svr)\n",
    "\n",
    "y_test= pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "#summarize the fit of the model on train data\n",
    "mape_train_svr_c3 = mean_absolute_percentage_error(y_train,y_pred_train1_svr)\n",
    "rmse_train_svr_c3 = sqrt(mean_squared_error(y_train,y_pred_train1_svr))\n",
    "mae_train_svr_c3 = metrics.mean_absolute_error(y_train,y_pred_train1_svr)\n",
    "\n",
    "# summarize the fit of the model on test data\n",
    "mape_test_svr_c3 = mean_absolute_percentage_error(y_test,y_pred_test1_svr)\n",
    "rmse_test_svr_c3 = sqrt(mean_squared_error(y_test,y_pred_test1_svr))\n",
    "mae_test_svr_c3 = metrics.mean_absolute_error(y_test,y_pred_test1_svr)\n",
    "\n",
    "# train scores\n",
    "print(\"The metrics for the training data are: \")\n",
    "print(mape_train_svr_c3)\n",
    "print(rmse_train_svr_c3)\n",
    "print(mae_train_svr_c3)\n",
    "\n",
    "# test scores\n",
    "print(\"The metrics for the testing data are: \")\n",
    "print(mape_test_svr_c3)\n",
    "print(rmse_test_svr_c3)\n",
    "print(mae_test_svr_c3)\n",
    "\n",
    "svr_time=time.time() - start_time\n",
    "print(\"--- %s seconds - Support Vector Regression ---\" % (svr_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your original dataset\n",
    "df = pd.read_excel(r\"UP08.xlsx\", index_col='Date_Time')\n",
    "df = df[['dissolvedoxygenmeasured']]\n",
    "df=df['2017-04-01':'2021-03-31']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "import numpy \n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-2):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back+2, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "def percentage_error(actual, predicted):\n",
    "    res = numpy.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data = df.loc['2017-04-01':'2020-03-31']\n",
    "test_data = df.loc['2020-04-01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=df.values\n",
    "X, Y = create_dataset(datasets, 5)\n",
    "\n",
    "train_size = 26304\n",
    "test_size = 8760\n",
    "trainX, testX = X[0:train_size], X[train_size:]\n",
    "trainY, testY = Y[0:train_size], Y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "start_time = time.time()\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "X_train=pd.DataFrame(trainX)\n",
    "Y_train=pd.DataFrame(trainY)\n",
    "X_test=pd.DataFrame(testX)\n",
    "Y_test=pd.DataFrame(testY)\n",
    "\n",
    "sc_X = MinMaxScaler()\n",
    "sc_y = MinMaxScaler()\n",
    "\n",
    "X= sc_X.fit_transform(X_train)\n",
    "y= sc_y.fit_transform(Y_train)\n",
    "X1= sc_X.transform(X_test)\n",
    "y1= sc_y.transform(Y_test)\n",
    "y=y.ravel()\n",
    "y1=y1.ravel()  \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X,y)\n",
    "y_pred_train_lr= lr.predict(X)\n",
    "y_pred_test_lr= lr.predict(X1)\n",
    "\n",
    "y_pred_train_lr=pd.DataFrame(y_pred_train_lr)\n",
    "y_pred_test_lr=pd.DataFrame(y_pred_test_lr)\n",
    "\n",
    "y1=pd.DataFrame(y1)\n",
    "y=pd.DataFrame(y)\n",
    "\n",
    "y_pred_test1_lr= sc_y.inverse_transform (y_pred_test_lr)\n",
    "y_pred_train1_lr=sc_y.inverse_transform (y_pred_train_lr)\n",
    "\n",
    "y_test= sc_y.inverse_transform (y1)\n",
    "y_train= sc_y.inverse_transform (y)\n",
    "\n",
    "y_pred_test1_rf=pd.DataFrame(y_pred_test1_lr)\n",
    "y_pred_train1_rf=pd.DataFrame(y_pred_train1_lr)\n",
    "\n",
    "y_test= pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "#summarize the fit of the model on train data\n",
    "mape_train_lr = mean_absolute_percentage_error(y_train,y_pred_train1_lr)\n",
    "rmse_train_lr = sqrt(mean_squared_error(y_train,y_pred_train1_lr))\n",
    "mae_train_lr = metrics.mean_absolute_error(y_train,y_pred_train1_lr)\n",
    "\n",
    "# summarize the fit of the model on test data\n",
    "mape_test_lr = mean_absolute_percentage_error(y_test,y_pred_test1_lr)\n",
    "rmse_test_lr = sqrt(mean_squared_error(y_test,y_pred_test1_lr))\n",
    "mae_test_lr = metrics.mean_absolute_error(y_test,y_pred_test1_lr)\n",
    "\n",
    "# train scores\n",
    "print(\"The metrics for the training data are: \")\n",
    "print(mape_train_lr)\n",
    "print(rmse_train_lr)\n",
    "print(mae_train_lr)\n",
    "\n",
    "# test scores\n",
    "print(\"The metrics for the testing data are: \")\n",
    "print(mape_test_lr)\n",
    "print(rmse_test_lr)\n",
    "print(mae_test_lr)\n",
    "\n",
    "lr_time=time.time() - start_time\n",
    "print(\"--- %s seconds - Linear Regression ---\" % (lr_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "start_time = time.time()\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "X_train=pd.DataFrame(trainX)\n",
    "Y_train=pd.DataFrame(trainY)\n",
    "X_test=pd.DataFrame(testX)\n",
    "Y_test=pd.DataFrame(testY)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "X= sc_X.fit_transform(X_train)\n",
    "y= sc_y.fit_transform(Y_train)\n",
    "X1= sc_X.transform(X_test)\n",
    "y1= sc_y.transform(Y_test)\n",
    "y=y.ravel()\n",
    "y1=y1.ravel()  \n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "svr.fit(X,y)\n",
    "y_pred_train_svr= svr.predict(X)\n",
    "y_pred_test_svr= svr.predict(X1)\n",
    "\n",
    "y_pred_train_svr=pd.DataFrame(y_pred_train_svr)\n",
    "y_pred_test_svr=pd.DataFrame(y_pred_test_svr)\n",
    "\n",
    "y1=pd.DataFrame(y1)\n",
    "y=pd.DataFrame(y)\n",
    "\n",
    "y_pred_test1_svr= sc_y.inverse_transform (y_pred_test_svr)\n",
    "y_pred_train1_svr=sc_y.inverse_transform (y_pred_train_svr)\n",
    "\n",
    "y_test= sc_y.inverse_transform (y1)\n",
    "y_train= sc_y.inverse_transform (y)\n",
    "\n",
    "y_pred_test1_rf=pd.DataFrame(y_pred_test1_svr)\n",
    "y_pred_train1_rf=pd.DataFrame(y_pred_train1_svr)\n",
    "\n",
    "y_test= pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "#summarize the fit of the model on train data\n",
    "mape_train_svr = mean_absolute_percentage_error(y_train,y_pred_train1_svr)\n",
    "rmse_train_svr = sqrt(mean_squared_error(y_train,y_pred_train1_svr))\n",
    "mae_train_svr = metrics.mean_absolute_error(y_train,y_pred_train1_svr)\n",
    "\n",
    "# summarize the fit of the model on test data\n",
    "mape_test_svr = mean_absolute_percentage_error(y_test,y_pred_test1_svr)\n",
    "rmse_test_svr = sqrt(mean_squared_error(y_test,y_pred_test1_svr))\n",
    "mae_test_svr = metrics.mean_absolute_error(y_test,y_pred_test1_svr)\n",
    "\n",
    "# train scores\n",
    "print(\"The metrics for the training data are: \")\n",
    "print(mape_train_svr)\n",
    "print(rmse_train_svr)\n",
    "print(mae_train_svr)\n",
    "\n",
    "# test scores\n",
    "print(\"The metrics for the testing data are: \")\n",
    "print(mape_test_svr)\n",
    "print(rmse_test_svr)\n",
    "print(mae_test_svr)\n",
    "\n",
    "svr_time=time.time() - start_time\n",
    "print(\"--- %s seconds - Support Vector Regression ---\" % (svr_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using whole dataset vs clusters for prediction \n",
    "print(mape_test_svr, (mape_test_svr_c1,mape_test_svr_c2,mape_test_svr_c3))\n",
    "print(rmse_test_svr, (rmse_test_svr_c1,rmse_test_svr_c2,rmse_test_svr_c3))\n",
    "print(mae_test_svr, (mae_test_svr_c1,mae_test_svr_c2,mae_test_svr_c3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using whole dataset vs clusters for prediction \n",
    "print(mape_test_lr, (mape_test_lr_c1,mape_test_lr_c2,mape_test_lr_c3))\n",
    "print(rmse_test_lr, (rmse_test_lr_c1,rmse_test_lr_c2,rmse_test_lr_c3))\n",
    "print(mae_test_lr, (mae_test_lr_c1,mae_test_lr_c2,mae_test_lr_c3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using whole dataset vs clusters for prediction \n",
    "print(mape_test_svr, (((4/12)*mape_test_svr_c1)+((3/12)*mape_test_svr_c2)+((5/12)*mape_test_svr_c3)))\n",
    "print(rmse_test_svr, (((4/12)*rmse_test_svr_c1)+((3/12)*rmse_test_svr_c2)+((5/12)*rmse_test_svr_c3)))\n",
    "print(mae_test_svr, (((4/12)*mae_test_svr_c1)+((3/12)*mae_test_svr_c2)+((5/12)*mae_test_svr_c3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using whole dataset vs clusters for prediction \n",
    "print(mape_test_lr, (((4/12)*mape_test_lr_c1)+((3/12)*mape_test_lr_c2)+((5/12)*mape_test_lr_c3)))\n",
    "print(rmse_test_lr, (((4/12)*rmse_test_lr_c1)+((3/12)*rmse_test_lr_c2)+((5/12)*rmse_test_lr_c3)))\n",
    "print(mae_test_lr, (((4/12)*mae_test_lr_c1)+((3/12)*mae_test_lr_c2)+((5/12)*mae_test_lr_c3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
