{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load your original dataset\n",
    "df = pd.read_excel(r\"UP08.xlsx\", index_col='Date_Time')\n",
    "df = df[['dissolvedoxygenmeasured']]\n",
    "df=df['2017-04-01':'2021-03-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Datasets:\n",
    "# Cluster 1: November, December, January, February\n",
    "# Cluster 2: June, July, August\n",
    "# Cluster 3: April, May, September, October, March"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Datasets:\n",
    "# Cluster 1: November, December, January, February"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your original dataset\n",
    "df = pd.read_excel(r\"UP08.xlsx\", index_col='Date_Time')\n",
    "df = df[['dissolvedoxygenmeasured']]\n",
    "df=df['2017-04-01':'2021-03-31']\n",
    "\n",
    "# Filter DataFrame for the months November, December, January, February\n",
    "df = df[df.index.month.isin([11, 12, 1, 2])]\n",
    "\n",
    "# Print or use the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Assuming you have a time series data stored in a pandas DataFrame called 'data'\n",
    "# with a column named 'value' containing the values\n",
    "\n",
    "# Convert the 'value' column to a numpy array\n",
    "# values = data['value'].to_numpy()\n",
    "\n",
    "# Plot ACF\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_acf(df['dissolvedoxygenmeasured'][:100], ax=ax,alpha=0.05)\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.title('Autocorrelation Function (ACF)')\n",
    "plt.show()\n",
    "\n",
    "# Plot PACF\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_pacf(df['dissolvedoxygenmeasured'][:100], ax=ax,alpha=0.05)\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Partial Autocorrelation')\n",
    "plt.title('Partial Autocorrelation Function (PACF)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df['2017-04-01':'2020-03-31']\n",
    "df_test=df['2020-04-01':]\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "import numpy \n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "def percentage_error(actual, predicted):\n",
    "    res = numpy.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "datasets=df.values\n",
    "X, Y = create_dataset(datasets, 8)\n",
    "\n",
    "train_size = df_train.shape[0]\n",
    "test_size =  df_test.shape[0]\n",
    "trainX, testX = X[0:train_size], X[train_size:]\n",
    "trainY, testY = Y[0:train_size], Y[train_size:]\n",
    "\n",
    "#  Random Forest Regressor\n",
    "start_time = time.time()\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "X_train=pd.DataFrame(trainX)\n",
    "Y_train=pd.DataFrame(trainY)\n",
    "X_test=pd.DataFrame(testX)\n",
    "Y_test=pd.DataFrame(testY)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "X= sc_X.fit_transform(X_train)\n",
    "y= sc_y.fit_transform(Y_train)\n",
    "X1= sc_X.transform(X_test)\n",
    "y1= sc_y.transform(Y_test)\n",
    "y=y.ravel()\n",
    "y1=y1.ravel()  \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(max_features=6)\n",
    "\n",
    "rfr.fit(X,y)\n",
    "y_pred_train_rfr= rfr.predict(X)\n",
    "y_pred_test_rfr= rfr.predict(X1)\n",
    "\n",
    "y_pred_train_rfr=pd.DataFrame(y_pred_train_rfr)\n",
    "y_pred_test_rfr=pd.DataFrame(y_pred_test_rfr)\n",
    "\n",
    "y1=pd.DataFrame(y1)\n",
    "y=pd.DataFrame(y)\n",
    "\n",
    "y_pred_test1_rfr= sc_y.inverse_transform (y_pred_test_rfr)\n",
    "y_pred_train1_rfr=sc_y.inverse_transform (y_pred_train_rfr)\n",
    "\n",
    "y_test= sc_y.inverse_transform (y1)\n",
    "y_train= sc_y.inverse_transform (y)\n",
    "\n",
    "y_pred_test1_rf=pd.DataFrame(y_pred_test1_rfr)\n",
    "y_pred_train1_rf=pd.DataFrame(y_pred_train1_rfr)\n",
    "\n",
    "y_test= pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "#summarize the fit of the model on train data\n",
    "mape_train_rfr_c1 = mean_absolute_percentage_error(y_train,y_pred_train1_rfr)\n",
    "rmse_train_rfr_c1 = sqrt(mean_squared_error(y_train,y_pred_train1_rfr))\n",
    "mae_train_rfr_c1 = metrics.mean_absolute_error(y_train,y_pred_train1_rfr)\n",
    "\n",
    "# summarize the fit of the model on test data\n",
    "mape_test_rfr_c1 = mean_absolute_percentage_error(y_test,y_pred_test1_rfr)\n",
    "rmse_test_rfr_c1 = sqrt(mean_squared_error(y_test,y_pred_test1_rfr))\n",
    "mae_test_rfr_c1 = metrics.mean_absolute_error(y_test,y_pred_test1_rfr)\n",
    "\n",
    "# train scores\n",
    "print(\"The metrics for the training data are: \")\n",
    "print(mape_train_rfr_c1)\n",
    "print(rmse_train_rfr_c1)\n",
    "print(mae_train_rfr_c1)\n",
    "\n",
    "# test scores\n",
    "print(\"The metrics for the testing data are: \")\n",
    "print(mape_test_rfr_c1)\n",
    "print(rmse_test_rfr_c1)\n",
    "print(mae_test_rfr_c1)\n",
    "\n",
    "rfr_time=time.time() - start_time\n",
    "print(\"--- %s seconds -#  Random Forest Regressor---\" % (rfr_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 2: June, July, August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your original dataset\n",
    "df = pd.read_excel(r\"UP08.xlsx\", index_col='Date_Time')\n",
    "df = df[['dissolvedoxygenmeasured']]\n",
    "df=df['2017-04-01':'2021-03-31']\n",
    "\n",
    "# Assuming you have already loaded and filtered your DataFrame df\n",
    "# If not, you can use the provided code to load and filter it\n",
    "\n",
    "# Filter DataFrame for the months 'June', 'July', 'August'\n",
    "df = df[df.index.month.isin([6, 7, 8])]\n",
    "\n",
    "# Print or use the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Assuming you have a time series data stored in a pandas DataFrame called 'data'\n",
    "# with a column named 'value' containing the values\n",
    "\n",
    "# Convert the 'value' column to a numpy array\n",
    "# values = data['value'].to_numpy()\n",
    "\n",
    "# Plot ACF\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_acf(df['dissolvedoxygenmeasured'][:100], ax=ax,alpha=0.05)\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.title('Autocorrelation Function (ACF)')\n",
    "plt.show()\n",
    "\n",
    "# Plot PACF\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_pacf(df['dissolvedoxygenmeasured'][:100], ax=ax,alpha=0.05)\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Partial Autocorrelation')\n",
    "plt.title('Partial Autocorrelation Function (PACF)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train=df['2017-04-01':'2020-03-31']\n",
    "df_test=df['2020-04-01':]\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "import numpy \n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "def percentage_error(actual, predicted):\n",
    "    res = numpy.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=df.values\n",
    "X, Y = create_dataset(datasets, 8)\n",
    "\n",
    "train_size = df_train.shape[0]\n",
    "test_size =  df_test.shape[0]\n",
    "trainX, testX = X[0:train_size], X[train_size:]\n",
    "trainY, testY = Y[0:train_size], Y[train_size:]\n",
    "\n",
    "#  Random Forest Regressor\n",
    "start_time = time.time()\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "X_train=pd.DataFrame(trainX)\n",
    "Y_train=pd.DataFrame(trainY)\n",
    "X_test=pd.DataFrame(testX)\n",
    "Y_test=pd.DataFrame(testY)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "X= sc_X.fit_transform(X_train)\n",
    "y= sc_y.fit_transform(Y_train)\n",
    "X1= sc_X.transform(X_test)\n",
    "y1= sc_y.transform(Y_test)\n",
    "y=y.ravel()\n",
    "y1=y1.ravel()  \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(max_features=4, max_depth=5, n_estimators=50 )\n",
    "\n",
    "rfr.fit(X,y)\n",
    "y_pred_train_rfr= rfr.predict(X)\n",
    "y_pred_test_rfr= rfr.predict(X1)\n",
    "\n",
    "y_pred_train_rfr=pd.DataFrame(y_pred_train_rfr)\n",
    "y_pred_test_rfr=pd.DataFrame(y_pred_test_rfr)\n",
    "\n",
    "y1=pd.DataFrame(y1)\n",
    "y=pd.DataFrame(y)\n",
    "\n",
    "y_pred_test1_rfr= sc_y.inverse_transform (y_pred_test_rfr)\n",
    "y_pred_train1_rfr=sc_y.inverse_transform (y_pred_train_rfr)\n",
    "\n",
    "y_test= sc_y.inverse_transform (y1)\n",
    "y_train= sc_y.inverse_transform (y)\n",
    "\n",
    "y_pred_test1_rf=pd.DataFrame(y_pred_test1_rfr)\n",
    "y_pred_train1_rf=pd.DataFrame(y_pred_train1_rfr)\n",
    "\n",
    "y_test= pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "#summarize the fit of the model on train data\n",
    "mape_train_rfr_c2 = mean_absolute_percentage_error(y_train,y_pred_train1_rfr)\n",
    "rmse_train_rfr_c2 = sqrt(mean_squared_error(y_train,y_pred_train1_rfr))\n",
    "mae_train_rfr_c2 = metrics.mean_absolute_error(y_train,y_pred_train1_rfr)\n",
    "\n",
    "# summarize the fit of the model on test data\n",
    "mape_test_rfr_c2 = mean_absolute_percentage_error(y_test,y_pred_test1_rfr)\n",
    "rmse_test_rfr_c2 = sqrt(mean_squared_error(y_test,y_pred_test1_rfr))\n",
    "mae_test_rfr_c2 = metrics.mean_absolute_error(y_test,y_pred_test1_rfr)\n",
    "\n",
    "# train scores\n",
    "print(\"The metrics for the training data are: \")\n",
    "print(mape_train_rfr_c2)\n",
    "print(rmse_train_rfr_c2)\n",
    "print(mae_train_rfr_c2)\n",
    "\n",
    "# test scores\n",
    "print(\"The metrics for the testing data are: \")\n",
    "print(mape_test_rfr_c2)\n",
    "print(rmse_test_rfr_c2)\n",
    "print(mae_test_rfr_c2)\n",
    "\n",
    "rfr_time=time.time() - start_time\n",
    "print(\"--- %s seconds -#  Random Forest Regressor---\" % (rfr_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 3: April, May, September, October, March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load your original dataset\n",
    "df = pd.read_excel(r\"UP08.xlsx\", index_col='Date_Time')\n",
    "df = df[['dissolvedoxygenmeasured']]\n",
    "df=df['2017-04-01':'2021-03-31']\n",
    "\n",
    "\n",
    "# Filter DataFrame for the months April, May, September, October, March\n",
    "\n",
    "df = df[df.index.month.isin([3, 4, 5, 9, 10])]\n",
    "\n",
    "# Print or use the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Assuming you have a time series data stored in a pandas DataFrame called 'data'\n",
    "# with a column named 'value' containing the values\n",
    "\n",
    "# Convert the 'value' column to a numpy array\n",
    "# values = data['value'].to_numpy()\n",
    "\n",
    "# Plot ACF\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_acf(df['dissolvedoxygenmeasured'][:100], ax=ax,alpha=0.05)\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.title('Autocorrelation Function (ACF)')\n",
    "plt.show()\n",
    "\n",
    "# Plot PACF\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_pacf(df['dissolvedoxygenmeasured'][:100], ax=ax,alpha=0.05)\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Partial Autocorrelation')\n",
    "plt.title('Partial Autocorrelation Function (PACF)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df['2017-04-01':'2020-03-31']\n",
    "df_test=df['2020-04-01':]\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "import numpy \n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "def percentage_error(actual, predicted):\n",
    "    res = numpy.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets=df.values\n",
    "X, Y = create_dataset(datasets, 9)\n",
    "\n",
    "train_size = df_train.shape[0]\n",
    "test_size =  df_test.shape[0]\n",
    "trainX, testX = X[0:train_size], X[train_size:]\n",
    "trainY, testY = Y[0:train_size], Y[train_size:]\n",
    "\n",
    "#  Random Forest Regressor\n",
    "start_time = time.time()\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "X_train=pd.DataFrame(trainX)\n",
    "Y_train=pd.DataFrame(trainY)\n",
    "X_test=pd.DataFrame(testX)\n",
    "Y_test=pd.DataFrame(testY)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "X= sc_X.fit_transform(X_train)\n",
    "y= sc_y.fit_transform(Y_train)\n",
    "X1= sc_X.transform(X_test)\n",
    "y1= sc_y.transform(Y_test)\n",
    "y=y.ravel()\n",
    "y1=y1.ravel()  \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(max_features=6)\n",
    "\n",
    "rfr.fit(X,y)\n",
    "y_pred_train_rfr= rfr.predict(X)\n",
    "y_pred_test_rfr= rfr.predict(X1)\n",
    "\n",
    "y_pred_train_rfr=pd.DataFrame(y_pred_train_rfr)\n",
    "y_pred_test_rfr=pd.DataFrame(y_pred_test_rfr)\n",
    "\n",
    "y1=pd.DataFrame(y1)\n",
    "y=pd.DataFrame(y)\n",
    "\n",
    "y_pred_test1_rfr= sc_y.inverse_transform (y_pred_test_rfr)\n",
    "y_pred_train1_rfr=sc_y.inverse_transform (y_pred_train_rfr)\n",
    "\n",
    "y_test= sc_y.inverse_transform (y1)\n",
    "y_train= sc_y.inverse_transform (y)\n",
    "\n",
    "y_pred_test1_rf=pd.DataFrame(y_pred_test1_rfr)\n",
    "y_pred_train1_rf=pd.DataFrame(y_pred_train1_rfr)\n",
    "\n",
    "y_test= pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "#summarize the fit of the model on train data\n",
    "mape_train_rfr_c3 = mean_absolute_percentage_error(y_train,y_pred_train1_rfr)\n",
    "rmse_train_rfr_c3 = sqrt(mean_squared_error(y_train,y_pred_train1_rfr))\n",
    "mae_train_rfr_c3 = metrics.mean_absolute_error(y_train,y_pred_train1_rfr)\n",
    "\n",
    "# summarize the fit of the model on test data\n",
    "mape_test_rfr_c3 = mean_absolute_percentage_error(y_test,y_pred_test1_rfr)\n",
    "rmse_test_rfr_c3 = sqrt(mean_squared_error(y_test,y_pred_test1_rfr))\n",
    "mae_test_rfr_c3 = metrics.mean_absolute_error(y_test,y_pred_test1_rfr)\n",
    "\n",
    "# train scores\n",
    "print(\"The metrics for the training data are: \")\n",
    "print(mape_train_rfr_c3)\n",
    "print(rmse_train_rfr_c3)\n",
    "print(mae_train_rfr_c3)\n",
    "\n",
    "# test scores\n",
    "print(\"The metrics for the testing data are: \")\n",
    "print(mape_test_rfr_c3)\n",
    "print(rmse_test_rfr_c3)\n",
    "print(mae_test_rfr_c3)\n",
    "\n",
    "rfr_time=time.time() - start_time\n",
    "print(\"--- %s seconds -#  Random Forest Regressor---\" % (rfr_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your original dataset\n",
    "df = pd.read_excel(r\"UP08.xlsx\", index_col='Date_Time')\n",
    "df = df[['dissolvedoxygenmeasured']]\n",
    "df=df['2017-04-01':'2021-03-31']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Assuming you have a time series data stored in a pandas DataFrame called 'data'\n",
    "# with a column named 'value' containing the values\n",
    "\n",
    "# Convert the 'value' column to a numpy array\n",
    "# values = data['value'].to_numpy()\n",
    "\n",
    "# Plot ACF\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_acf(df['dissolvedoxygenmeasured'][:100], ax=ax,alpha=0.05)\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.title('Autocorrelation Function (ACF)')\n",
    "plt.show()\n",
    "\n",
    "# Plot PACF\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_pacf(df['dissolvedoxygenmeasured'][:100], ax=ax,alpha=0.05)\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Partial Autocorrelation')\n",
    "plt.title('Partial Autocorrelation Function (PACF)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "import numpy \n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "def percentage_error(actual, predicted):\n",
    "    res = numpy.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return numpy.mean(numpy.abs(percentage_error(numpy.asarray(y_true), numpy.asarray(y_pred)))) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data = df.loc['2017-04-01':'2020-03-31']\n",
    "test_data = df.loc['2020-04-01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "datasets=df.values\n",
    "X, Y = create_dataset(datasets, 5)\n",
    "\n",
    "train_size = train_data.shape[0]\n",
    "test_size =  test_data.shape[0]\n",
    "trainX, testX = X[0:train_size], X[train_size:]\n",
    "trainY, testY = Y[0:train_size], Y[train_size:]\n",
    "\n",
    "#  Random Forest Regressor\n",
    "start_time = time.time()\n",
    "\n",
    "numpy.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "X_train=pd.DataFrame(trainX)\n",
    "Y_train=pd.DataFrame(trainY)\n",
    "X_test=pd.DataFrame(testX)\n",
    "Y_test=pd.DataFrame(testY)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "\n",
    "X= sc_X.fit_transform(X_train)\n",
    "y= sc_y.fit_transform(Y_train)\n",
    "X1= sc_X.transform(X_test)\n",
    "y1= sc_y.transform(Y_test)\n",
    "y=y.ravel()\n",
    "y1=y1.ravel()  \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(max_features=5)\n",
    "\n",
    "rfr.fit(X,y)\n",
    "y_pred_train_rfr= rfr.predict(X)\n",
    "y_pred_test_rfr= rfr.predict(X1)\n",
    "\n",
    "y_pred_train_rfr=pd.DataFrame(y_pred_train_rfr)\n",
    "y_pred_test_rfr=pd.DataFrame(y_pred_test_rfr)\n",
    "\n",
    "y1=pd.DataFrame(y1)\n",
    "y=pd.DataFrame(y)\n",
    "\n",
    "y_pred_test1_rfr= sc_y.inverse_transform (y_pred_test_rfr)\n",
    "y_pred_train1_rfr=sc_y.inverse_transform (y_pred_train_rfr)\n",
    "\n",
    "y_test= sc_y.inverse_transform (y1)\n",
    "y_train= sc_y.inverse_transform (y)\n",
    "\n",
    "y_pred_test1_rf=pd.DataFrame(y_pred_test1_rfr)\n",
    "y_pred_train1_rf=pd.DataFrame(y_pred_train1_rfr)\n",
    "\n",
    "y_test= pd.DataFrame(y_test)\n",
    "\n",
    "\n",
    "#summarize the fit of the model on train data\n",
    "mape_train_rfr = mean_absolute_percentage_error(y_train,y_pred_train1_rfr)\n",
    "rmse_train_rfr = sqrt(mean_squared_error(y_train,y_pred_train1_rfr))\n",
    "mae_train_rfr = metrics.mean_absolute_error(y_train,y_pred_train1_rfr)\n",
    "\n",
    "# summarize the fit of the model on test data\n",
    "mape_test_rfr = mean_absolute_percentage_error(y_test,y_pred_test1_rfr)\n",
    "rmse_test_rfr = sqrt(mean_squared_error(y_test,y_pred_test1_rfr))\n",
    "mae_test_rfr = metrics.mean_absolute_error(y_test,y_pred_test1_rfr)\n",
    "\n",
    "# train scores\n",
    "print(\"The metrics for the training data are: \")\n",
    "print(mape_train_rfr)\n",
    "print(rmse_train_rfr)\n",
    "print(mae_train_rfr)\n",
    "\n",
    "# test scores\n",
    "print(\"The metrics for the testing data are: \")\n",
    "print(mape_test_rfr)\n",
    "print(rmse_test_rfr)\n",
    "print(mae_test_rfr)\n",
    "\n",
    "rfr_time=time.time() - start_time\n",
    "print(\"--- %s seconds -#  Random Forest Regressor---\" % (rfr_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using whole dataset vs clusters for prediction \n",
    "print(mape_test_rfr, mape_test_rfr_c1,mape_test_rfr_c2,mape_test_rfr_c3)\n",
    "print(rmse_test_rfr, rmse_test_rfr_c1,rmse_test_rfr_c2,rmse_test_rfr_c3)\n",
    "print(mae_test_rfr, mae_test_rfr_c1,mae_test_rfr_c2,mae_test_rfr_c3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using whole dataset vs clusters for prediction \n",
    "print(mape_test_rfr, (((4/12)*mape_test_rfr_c1)+((3/12)*mape_test_rfr_c2)+((5/12)*mape_test_rfr_c3)))\n",
    "print(rmse_test_rfr, (((4/12)*rmse_test_rfr_c1)+((3/12)*rmse_test_rfr_c2)+((5/12)*rmse_test_rfr_c3)))\n",
    "print(mae_test_rfr, (((4/12)*mae_test_rfr_c1)+((3/12)*mae_test_rfr_c2)+((5/12)*mae_test_rfr_c3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
